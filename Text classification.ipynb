{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация отрывков текста\n",
    "\n",
    "Программа, которая по отрывку текста говорит, принадлежит ли он перу Льва Толстого или Ильи Ильфа и Евгения Петрова.\n",
    "\n",
    "#### Подготовка данных\n",
    "\n",
    "Было скачано 4MB книг Ильи Ильфа и Евгения Петрова и 6MB книг Льва Толстого. Далее все тексты были разбиты на отрывки по 100 слов в каждом. Понятно, что чем больше слов в отрывке, тем проще определить автора. Были попробованы модели, обученные на отрывках различной длины. Оптимальным с точки зрения качества классификации и здравого смысла значением длины отрывка оказалось 100 слов.\n",
    "\n",
    "Также все данные были поделены на обучающую, валидационную и тестовую выборки в соотношении 70/15/15. Отдельно валидационная и тестовая выборки необходимы для того, чтобы не переобучаться на валидационную выборку при подборе гиперпараметров модели, и оценивать итоговое качество модели по тестовой выборке.\n",
    "\n",
    "#### Векторные представления текстовых данных\n",
    "\n",
    "Для того, чтобы обучать модели, необходимо было представить текстовые данные в числовом виде. Для этого использовалась модель gensim.models.doc2vec, переводящая текстовые документы в вектора. Модель обучалась на двух текстах - книги Ильфа и Петрова и книги Толстого.\n",
    "\n",
    "#### Метрика качества\n",
    "\n",
    "Так как хотелось предсказывать вероятность принадлежности отрывка к одному из классов, то использовалась метрика AUC ROC.\n",
    "\n",
    "#### Обучение моделей классификации\n",
    "\n",
    "Было попробовано три модели: градиентный бустинг XGBoost, логистическая регрессия и метод опорных векторов.\n",
    "\n",
    "Градиентный бустинг показал качество **0.87444** на тестовых данных. Логистическая регрессия: **0.88488**. SVM: **0.88509**. Три решения были скомбинированы ансамблем, итоговое качество на тестовых данных получилось **0.88686**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymorphy2\n",
    "from time import time\n",
    "\n",
    "from gensim.models import doc2vec\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_names_Ilf_Petrov = ['Data/Ilf_Petrov_1001_den_ili_novaya_Shacherezada.txt',\n",
    "                         'Data/Ilf_Petrov_Dvenadcat_stulev.txt',\n",
    "                         'Data/Ilf_Petrov_Neobyknovennye_istorii_iz_zhizni_goroda_kolokolamska.txt',\n",
    "                         'Data/Ilf_Petrov_Odnoetazhnaya_America.txt',\n",
    "                         'Data/Ilf_Petrov_Svetlaya_lichnost.txt',\n",
    "                         'Data/Ilf_Petrov_Zolotoj_telenok.txt']\n",
    "file_names_Tolstoy = ['Data/Tolstoy_Anna_Karenina.txt',\n",
    "                      'Data/Tolstoy_Vojna_i_mir_Tom_1.txt',\n",
    "                      'Data/Tolstoy_Voskresenie.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Transforms words from text to normal form\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text (string): text\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    string: text (list of words) with words in normal form\n",
    "    \"\"\"\n",
    "    \n",
    "    words = ''.join(char for char in text.lower() if char.isalpha() or char == ' ').split()\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    return [morph.parse(word)[0].normal_form for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts(file_names, batch_length, display=False):\n",
    "    \"\"\"\n",
    "    Reads texts from files, normalizes them and returns texts in batches\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_names: list of strings\n",
    "    batch_length: number of words in a batch\n",
    "    display (boolean): whether to display processed information or not\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    texts: numpy.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time()\n",
    "    texts = []\n",
    "    for j, file_name in enumerate(file_names):\n",
    "        curr_text = [] # current batch\n",
    "        n_words = 0 # count number of words in a batch\n",
    "        \n",
    "        file = open(file_name, 'r')\n",
    "        for line in file:\n",
    "            norm_line = normalize_text(line)\n",
    "            \n",
    "            while n_words + len(norm_line) > batch_length:\n",
    "                rem_len = batch_length - n_words # remaining length of the batch\n",
    "                curr_text += norm_line[:rem_len]\n",
    "                texts.append(curr_text)\n",
    "                \n",
    "                norm_line = norm_line[rem_len:]\n",
    "                curr_text = []\n",
    "                n_words = 0\n",
    "            \n",
    "            n_words += len(norm_line)\n",
    "            curr_text += norm_line\n",
    "\n",
    "        if display:\n",
    "            print('File #{} has been processed (time passed: {})'.format(j, time() - start_time))\n",
    "\n",
    "    return np.array(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File #0 has been processed (time passed: 37.835206747055054)\n",
      "File #1 has been processed (time passed: 558.6166124343872)\n",
      "File #2 has been processed (time passed: 625.0489070415497)\n",
      "File #3 has been processed (time passed: 1036.5923702716827)\n",
      "File #4 has been processed (time passed: 1109.520709991455)\n",
      "File #5 has been processed (time passed: 1560.5091240406036)\n"
     ]
    }
   ],
   "source": [
    "texts_Ilf_Petrov = read_texts(file_names_Ilf_Petrov, batch_length=100, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File #0 has been processed (time passed: 637.1563684940338)\n",
      "File #1 has been processed (time passed: 1124.6750407218933)\n",
      "File #2 has been processed (time passed: 1831.6201725006104)\n"
     ]
    }
   ],
   "source": [
    "texts_Tolstoy = read_texts(file_names_Tolstoy, batch_length=100, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack((texts_Ilf_Petrov, texts_Tolstoy))\n",
    "target = np.array([0] * len(texts_Ilf_Petrov) + [1] * len(texts_Tolstoy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.3, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_valid, data_test, target_valid, target_test = train_test_split(data_test, target_test,\n",
    "                                                                    test_size=0.5, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8298, 5808, 1245, 1245)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(data_train), len(data_valid), len(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили 8298 объектов, из них: 5808 объектов для обучения и 1245 для валидации и 1245 для теста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(documents):\n",
    "    \"\"\"\n",
    "    Preprocess data (already normalized) before it can be used in gensim.models.doc2vec.Doc2Vec\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        documents: list of texts (where text is a list of words)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        list of tagged documents\n",
    "    \"\"\"\n",
    "    \n",
    "    tagged_documents = []\n",
    "    for i, document in enumerate(documents):\n",
    "        tagged_documents.append(doc2vec.TaggedDocument(document, [i]))\n",
    "    return tagged_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_data = [data_train[target_train == 0].flatten(),\n",
    "            data_train[target_train == 1].flatten()]\n",
    "tagged_data = preprocess_data(d2v_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec_size = 100\n",
    "d2v_model = doc2vec.Doc2Vec(tagged_data, size=vec_size, window=8, min_count=3, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразуем все выборки в вектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_d2v = np.empty((0, vec_size))\n",
    "for text in data_train:\n",
    "    data_train_d2v = np.vstack((data_train_d2v, d2v_model.infer_vector(text)))\n",
    "\n",
    "data_valid_d2v = np.empty((0, vec_size))\n",
    "for text in data_valid:\n",
    "    data_valid_d2v = np.vstack((data_valid_d2v, d2v_model.infer_vector(text)))\n",
    "\n",
    "data_test_d2v = np.empty((0, vec_size))\n",
    "for text in data_test:\n",
    "    data_test_d2v = np.vstack((data_test_d2v, d2v_model.infer_vector(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clf_new_document(document, d2v_model, clf_model):\n",
    "    \"\"\"\n",
    "    Classifies new text document\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    document: numpy.ndarray of words\n",
    "    d2v_model: gensim.models.doc2vec.Doc2Vec\n",
    "    clf_model: sklearn trained model with predict_proba method\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    float: probability of class 1\n",
    "    \"\"\"\n",
    "    \n",
    "    # normalize document text\n",
    "    norm_document = normalize_text(' '.join(document))[0]\n",
    "    \n",
    "    # get vector for new document with doc2vec model\n",
    "    vec = d2v_model.infer_vector(norm_document.split())\n",
    "    \n",
    "    # predict class with trained classifier model \n",
    "    return clf_model.predict_proba(vec.reshape(1, -1))[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': [4, 5],\n",
    "              'n_estimators': [80, 90],\n",
    "              'min_child_weight': [2, 3],\n",
    "              'gamma': [0.001, 0.01],\n",
    "              'reg_lambda': [2, 3],\n",
    "              'reg_alpha': [1, 2],\n",
    "              'learning_rate': [0.1, 0.2],\n",
    "              'nthread': [10],\n",
    "              'seed': [17]}\n",
    "start_time = time()\n",
    "scores = []\n",
    "for i, params in enumerate(ParameterGrid(param_grid)):\n",
    "    clf_xgb = xgb.XGBClassifier(**params)\n",
    "    clf_xgb.fit(data_train_d2v, target_train)\n",
    "    \n",
    "    pred_xgb = []\n",
    "    for vec in data_valid_d2v:\n",
    "        pred_xgb.append(clf_xgb.predict_proba(vec.reshape(1, -1))[0][1])\n",
    "    \n",
    "    scores.append(roc_auc_score(target_valid, pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'gamma': 0.001,\n",
       "  'learning_rate': 0.2,\n",
       "  'max_depth': 4,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 90,\n",
       "  'nthread': 10,\n",
       "  'reg_alpha': 1,\n",
       "  'reg_lambda': 3,\n",
       "  'seed': 17},\n",
       " 0.87263150374782927)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param = ParameterGrid(param_grid)[np.argmax(np.array(scores))]\n",
    "best_param, max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb_best = xgb.XGBClassifier(**best_param)\n",
    "clf_xgb_best.fit(data_train_d2v, target_train)\n",
    "\n",
    "pred_xgb = []\n",
    "for vec in data_test_d2v:\n",
    "    pred_xgb.append(clf_xgb_best.predict_proba(vec.reshape(1, -1))[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87443706123890685"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(target_test, pred_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "scores = []\n",
    "Cs = np.linspace(1000, 2000, 100)\n",
    "for C in Cs:\n",
    "    clf_log_reg = LogisticRegression(C=C, random_state=17)\n",
    "    clf_log_reg.fit(data_train_d2v, target_train)\n",
    "    \n",
    "    pred_log_reg = []\n",
    "    for vec in data_valid_d2v:\n",
    "        pred_log_reg.append(clf_log_reg.predict_proba(vec.reshape(1, -1))[0][1])\n",
    "    \n",
    "    scores.append(roc_auc_score(target_valid, pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030.3030303030303, 0.89127997713934026)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_C_log_reg = Cs[np.argmax(np.array(scores))]\n",
    "best_C_log_reg, max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_log_reg_best = LogisticRegression(C=best_C_log_reg, random_state=17)\n",
    "clf_log_reg_best.fit(data_train_d2v, target_train)\n",
    "\n",
    "pred_log_reg = []\n",
    "for vec in data_test_d2v:\n",
    "    pred_log_reg.append(clf_log_reg_best.predict_proba(vec.reshape(1, -1))[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88488178286017038"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(target_test, pred_log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "scores = []\n",
    "Cs = np.linspace(5000, 10000, 20)\n",
    "for C in Cs:\n",
    "    clf_svm = SVC(C=C, probability=True, random_state=17)\n",
    "    clf_svm.fit(data_train_d2v, target_train)\n",
    "    \n",
    "    pred_svm = []\n",
    "    for vec in data_valid_d2v:\n",
    "        pred_svm.append(clf_svm.predict_proba(vec.reshape(1, -1))[0][1])\n",
    "    \n",
    "    scores.append(roc_auc_score(target_valid, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5526.3157894736842, 0.89231172927703173)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_C_svm = Cs[np.argmax(np.array(scores))]\n",
    "best_C_svm, max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm_best = SVC(C=best_C_svm, probability=True, random_state=17)\n",
    "clf_svm_best.fit(data_train_d2v, target_train)\n",
    "\n",
    "pred_svm = []\n",
    "for vec in data_test_d2v:\n",
    "    pred_svm.append(clf_svm.predict_proba(vec.reshape(1, -1))[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88508598613625344"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(target_test, pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_xgb_best = xgb.XGBClassifier(**best_param)\n",
    "clf_log_reg_best = LogisticRegression(C=best_C_log_reg, random_state=17)\n",
    "clf_svm_best = SVC(C=best_C_svm, probability=True, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ens_best = VotingClassifier(estimators=[('xgb', clf_xgb_best),\n",
    "                                            ('lr', clf_log_reg_best),\n",
    "                                            ('svm', clf_svm_best)], voting='soft')\n",
    "clf_ens_best.fit(data_train_d2v, target_train)\n",
    "\n",
    "pred_ens = []\n",
    "for vec in data_test_d2v:\n",
    "    pred_ens.append(clf_ens_best.predict_proba(vec.reshape(1, -1))[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88686310653892009"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(target_test, pred_ens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
